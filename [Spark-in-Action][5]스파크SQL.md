# Spark SQL

---
## 학습목표
1. DataFrame을 생성하는 방법에 대해 알 수 있다.
2. DataFrame API 사용법에 대해 알 수 있다.
3. DataSet에 대해 알 수 있다.
4. 외부 데이터를 로드 및 저장하는 방법에 대해 알 수 있다.
---

## 1. DataFrame 다루기
- RDD는 spark 전용 분산 컬렉션, 1. 불변성, 2. 복원성, 3. 분산의 특징을 가지고 있다 (한 번 생성된 RDD는 절대 바뀌지 않는 immutable한 특징을 가지고 있다. 불변성 & 복원성을 통해서 분산 시스템에서 가장 중요한 장애 대응을 할 수 있다.)
    - 어떻게?
          - 일반적인 분산 프레임워크에서는 노드에 장애가 발생하면 replica를 가져와서 데이터를 복원하는데,
          - spark의 RDD는 데이터셋 자체를 중복 저장하는게 아니라, 데이터셋을 만드는 데 사용된 transformation 연산자의 로그를 남기는 방식으로 장애 대응을 한다.
          - 스파크에서는 일부 노드에 장애가 발생하면, 해당 노드가 가진 데이터셋만 다시 계산해서 RDD를 복원한다.

          - transformation 연산자 : 항상 새로운 RDD 객체를 만든다.
          - action 연산자 : 연산자를 호출한 프로그램으로 계산 결과를 반환하거나 RDD 요소에 특정 작업을 수행하려고 실제 계산을 시작한다.
- RDD는 데이터를 직접 다룰 수 있는 스파크 하위 레벨 interface의 핵심이다

- 스파크 v1.3에서 소개된 **`DataFrame`** 은 컬럼 이름과 타입이 지정된 테이블 형식의 분산 정형 데이터를 손쉽게 다룰 수 있는 상위 레벨 interface를 제공한다
<br/><br/>

- DataFrame은 RDD와 유사할뿐만 아니라 RDD를 기반으로 동작한다.

### DataFrame 생성하기
#### 1. 기존 RDD를 변환하는 방법
- DataFrame을 생성할 때는 데이터를 먼저 RDD로 로드한 후에 DataFrame으로 변환하는 방법을 가장 많이 사용한다.
- 비정형 데이터에 DataFrame API를 사용하려면 이 데이터를 RDD로 로드하고 변환한 후에 이 RDD에서 DataFrame을 생성해야 한다.

##### RDD에서 DataFrame을 생성하는 3가지 방법
1. 로우의 데이터를 튜플 형태로 저장한 RDD를 사용하는 방법
2. case 클래스를 사용하는 방법
3. 스키마를 명시적으로 지정하는 방법

#### 2. SQL 쿼리를 실행하는 방법
#### 3. 외부 데이터에서 로드하는 방법
